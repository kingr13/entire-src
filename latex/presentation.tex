\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage{default}
\newcommand*{\Comb}[2]{{}^{#1}C_{#2}}%

\usepackage{amsmath}
\usepackage{pst-node}

\usepackage{color}
\definecolor{myblue}{rgb}{.8, .8, 1}
\definecolor{mygreen}{rgb}{.8, 1, 0.8}

\usepackage{amsmath}
\usepackage{empheq}


\newlength\mytemplen
\newsavebox\mytempbox

\makeatletter
\newcommand\mybluebox{%
    \@ifnextchar[%]
       {\@mybluebox}%
       {\@mybluebox[0pt]}}

\def\@mybluebox[#1]{%
    \@ifnextchar[%]
       {\@@mybluebox[#1]}%
       {\@@mybluebox[#1][0pt]}}

\def\@@mybluebox[#1][#2]#3{
    \sbox\mytempbox{#3}%
    \mytemplen\ht\mytempbox
    \advance\mytemplen #1\relax
    \ht\mytempbox\mytemplen
    \mytemplen\dp\mytempbox
    \advance\mytemplen #2\relax
    \dp\mytempbox\mytemplen
    \colorbox{myblue}{\hspace{1em}\usebox{\mytempbox}\hspace{1em}}}

\makeatother


\psset{arrowscale=2,arrows=->}
\def\VPh{\vphantom{\displaystyle\sum_{i=n}^m {i^2}}}
\def\psBox#1#2{\psframebox[fillcolor=#1,fillstyle=solid]{\VPh\displaystyle#2}}

\usetheme{Warsaw}
\useoutertheme{infolines}

\title{Named Entity Recognition and Tagging}
\subtitle{An Overview}
\author[A. Madaan]{Aman Madaan}
\institute[IITB]{
  Indian Institute of Technology Bombay, Mumbai
}
\date{January 23rd, 2014}

\begin{document}
\maketitle

\begin{frame}
\frametitle{Table of Contents}
\tableofcontents[currentsection]
\begin{itemize}
  \item Recognition and Tagging
  \item Named Entity Recognition \bigskip
    \begin{itemize}
      \item Problem statement \bigskip
      \item Solutions \bigskip
      \item NER as a Sequence labelling problem : HMM to MEMM to CRF
    \end{itemize}
\bigskip
  \item Named Entity Tagging \bigskip
    \begin{itemize}
      \item 
      Collective Annotation of WikiPedia Entities in Web Text \\ Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and Soumen Chakrabarti
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Recognition and Tagging : Two step problem}
 \begin{center}
\textcolor{blue}{Michael Jordan is a Professor at Berkeley}
   \end{center}

\end{frame}

\begin{frame}
 \frametitle{Recognition and Tagging : Two step problem}
 \begin{center}
\textcolor{blue}{Michael Jordan is a Professor at Berkeley}
   \end{center}

 \begin{itemize}  
  \item Step 1 : \textbf{Identify} entities $\righteq$ 

  \medskip
  \textcolor{green}{Michael Jordan\_PERSON} is a professor at \textcolor{green}{Berkeley\_INSTITUTION} \medskip
  
\end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Recognition and tagging : Two step problem}
 \begin{center}
\textcolor{blue}{Michael Jordan is a Professor at Berkeley}
   \end{center}

 \begin{itemize}  
  \item Step 1 : \textbf{Identify} entities $\righteq$ 
  \medskip
  
  \textcolor{green}{Michael Jordan\_PERSON} is a professor at \textcolor{green}{Berkeley\_INSTITUTION} \medskip
  \item Step 2 : \textbf{Link} entities to knowledge bases : 
  \medskip
  
  \textcolor{red}{Michael Jordan\_ENTITY} (\url{http://en.wikipedia.org/wiki/Michael_I._Jordan})  is a professor at  
  \textcolor{red}{Berkeley\_ENTITY} (\url{http://en.wikipedia.org/wiki/University_of_California,_Berkeley})
\end{itemize}

\end{frame}

\begin{frame}
 \begin{center}
  Collective Annotation of WikiPedia Entities in Web Text \\ Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and Soumen Chakrabarti
  \\Discussion
 \end{center}

\end{frame}

\begin{frame}
 \frametitle{Key Intuition : Topical Coherence}
 \begin{itemize}
  \item A document is usually about one topic \bigskip
  \item Disambiguating each entity using the local clues misses out on a major piece of information : Topic of a page \bigskip
  \item A page is usually has one topic, you can expect all the entities to be \emph{related} to the topic \emph{somehow} \bigskip
  \end{itemize}
Eg. : Michael Jackson : 30 Disambiguations http://en.wikipedia.org/wiki/Michael\_Jackson\_(disambiguation)
  John Paul : 
  But if they are mentioned on the same page, the page is most likely about Christianity, A big hint towards disambiguating \textbf{both} of them
  
 
  \end{frame}
 
\begin{frame}
 \frametitle{Challenges}
 \begin{itemize}
  \item Capturing local compatibility
  \item Inculcating topical coherence in the overall objective
 \end{itemize}

\end{frame}

\begin{frame}
 \frametitle{Challenges}
 \begin{itemize}
  \item Capturing local compatibility
  \begin{itemize}
   \item \textcolor{blue}{Create a scoring function to rank possible candidates}
  \end{itemize}

  \item Inculcating topical coherence in the overall objective
 \end{itemize}

\end{frame}


\begin{frame}
 \frametitle{Challenges}
 \begin{itemize}
  \item Capturing local compatibility
  \begin{itemize}
   \item \textcolor{blue}{Create a scoring function to rank possible candidates}
  \end{itemize}

  \item Inculcating topical coherence in the overall objective

  \begin{itemize}
   \item \textcolor{blue}{Define Topical coherence}
  \end{itemize}

  \end{itemize}

\end{frame}

\begin{frame}
 \frametitle{Local compatibility}
 \begin{itemize}
  \item $s$ : Spot, an Entity to be disambiguated (Christian leader John Paul) \bigskip 
  \item $\gamma$ : An entity label value (\url{http://en.wikipedia.org/wiki/Pope_John_Paul_II}) 
 \item $f_s(\gamma)$ : A feature function that creates a vector of features
 \end{itemize}

  
\end{frame}

\begin{frame}

\frametitle{Local compatibility : Feature design} 
\begin{itemize}
 \item 1. Take
\begin{itemize} 
 \item Text from the first descriptive paragraph of $\gamma$
  \item Text from the whole page for $\gamma$
  \item Anchor text within Wikipedia for $\gamma$.
  \item Anchor text and 5 tokens around $\gamma$ 
 \end{itemize}
 
 \item 2. Apply each of the following operation with one argument as Spot
    \begin{itemize}
      \item{Dot-product between word count vectors}
      \item{Cosine similarity in TFIDF vector space}
      \item{Jaccard similarity between word sets}
 \end{itemize} 
 \end{itemize}
 Total 12 Features (3 operations, 4 argument pairs) + Sense Probability Prior\footnote{Obtained by counting intra wiki links}
 
\end{frame}

\begin{frame}
 \frametitle{Compatibility Score}
 \begin{itemize}
 \item Local compatibility score between a spot $s$ and a candidate is given by $w^{T}f_s(\gamma)$
 \item Thus, candidate is picked by $argmax_{\gamma\in\Gamma}w^{T}f_s(\gamma)$
 \item $w$ is trained using an SVM like training objective
 \begin{center} $w^{T}f_s(\gamma) - w^{T}f_s(\gamma) \geq 1 - \epsilon_s$ \end{center}
 \end{itemize}
 
 \end{frame}

 \begin{frame}
  \frametitle{Defining topic Relatedness}
  \begin{itemize}
   \item We need some notion of capturing the fact that 2 topics are related to each other \medskip
   \item Given
   \begin{itemize}
    \item $g(\gamma)$ : Set of wikipedia pages that link to $\gamma$
    \item $c :$ Total number of Wikipedia pages
    \item $r(\gamma, \gamma') :$ Relatedness of topics $\gamma$ and $\gamma'$
   \end{itemize}\bigskip

    
   \item Define $ r(\gamma, \gamma') = \frac{log|g(\gamma) \bigcap g(\gamma')| - log(max\{|g(\gamma)|, |(\gamma')|\})} {log c - log(min\{|g(\gamma)|, |(\gamma')|\})}$ 

  \end{itemize}

  
 \end{frame}

 
 \begin{frame}
  \frametitle{The Dominant Topic Model}
  \begin{itemize}
   \item Need to define a collective score based on pairwise topical coherence of all $\gamma_s$ used for labeling. \medskip
   \item The pairwise topical coherence, $r(\gamma_s, \gamma_s')$ is as defined above.\medskip
   \item For a page, overall topical coherence : \begin{center}\medskip
                                                  $\Sigma_{s \neq s' \in S_0}r(\gamma_s, \gamma_s')$
                                                 \end{center}
   \item Can be written as clique potential as in case of node potential\medskip
      \begin{center}
	$exp(\Sigma_{s \neq s' \in S_0}r(\gamma_s, \gamma_s'))$
      \end{center}

  \end{itemize}

 \end{frame}

 \begin{frame}
  \frametitle{The Optimization objective}
 \begin{center}
 \begin{empheq}[box={\mybluebox[5pt]}]{equation*}
  \frac{1}{\binom{|S_0|}{2}}\Sigma_{s \neq s' \in S_0}r(\gamma_s, \gamma_s') + \frac{1}{|S_0|}\Sigma_{s \in S_0}w^{T}f_s(\gamma)
 \end{empheq}
 \includegraphics[height = 5 cm]{objective}\footnote{From \ref{paper}}
  \end{center}

 
 \end{frame}

 \begin{frame}
  \frametitle{Solving the optimization objective}
 \end{frame}

 \begin{frame}
  \frametitle{Experiments : Data preparation}
  \begin {itemize}
  \item August 2008 version of WikiPedia used, 5.15 million entity IDs. \medskip
  \item Filter out IDs composed of verbs, adverbs, conjunctions etc. \medskip
  \item Create a trie from IDs. \medskip
  \item Identify spots (\emph{NER}) by tokenizing the document and then matching spots with the trie. 
  \end{itemize}
  
 \end{frame}

 \begin{frame}
  \frametitle{Experiments : Preparing Ground Truth Collection}
  \begin {itemize}
  \item Need data annotated with links to Wikipedia \medskip
  \item Done manually, pages obtained from popular links across various domains \medskip
  \item 19, 000 annotations marked, 40\% marked NA, 3800 distinct entities used \medskip
  \end{itemize}
 \begin{tabular}{| l | c | r |}
\hline
 Number of documents & 107 \\
Total number of spots & 17,200 \\
Spot per 100 tokens & 30 \\
Average ambiguity per Spot & 5.3\\
\hline
\end{tabular}
  
 \end{frame}

 \begin{frame}
  \frametitle{Results : Only Local disambiguation}
  \begin{itemize}
  \item Local approach performs well
  \end{itemize}
  
  \begin{center}
  \begin{empheq}[box={\mybluebox[5pt]}]{equation*}
  \gamma_0 \leftarrow argmax_{\gamma\in\Gamma_s}  w^{T}f_s(\gamma)
  \end{empheq}
  \begin{empheq}[box={\mybluebox[5pt]}]{equation*}
  \text{if }  w^{T}f_s(\gamma_0) > \rho_{NA} \text{ then return }\gamma_0 \text{ else return NA}
  \end{empheq}
  \includegraphics[height = 4 cm]{localperf}\footnote{from \ref{thepaper}}
  \end{center}

 \end{frame}

 \begin{frame}
  \frametitle{LP vs Hill climbing approach}
  \begin{itemize}
   \item Hill climbing and LP are equivalent
  \end{itemize}

  \begin{center}
  \includegraphics[height = 5 cm]{hillversuslp}
  \end{center}

 \end{frame}

\begin{frame}
\frametitle{References}
\begin{thebibliography}{9}
\setbeamertemplate{bibliography item}[text]
\bibitem{A} \label{thepaper} Collective Annotation of Wikipedia Entities in Web Text \\
Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and Soumen Chakrabarti, IIT Bombay

\setbeamertemplate{bibliography item}[online]
\bibitem{B}  \label{thesite} \url{http://www.cse.iitb.ac.in/~soumen/OWI/Slides/}

\setbeamertemplate{bibliography item}[text]
\bibitem{C} \label{thesurvey} William Cohen's Survey available at \ref{thesite}

\end{thebibliography}
\end{frame}
\end{document}
